#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CHP Traffic -> Telegram notifier (v5.1)
- –í—ã–±–∏—Ä–∞–µ—Ç Communications Center (ASP.NET postback)
- –§–∏–ª—å—Ç—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ Collision
- –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–µ–ª–∞–µ—Ç postback –ø–æ "Details"
- –ò–∑ HTML Details:
  * –¥–æ—Å—Ç–∞—ë—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ —Å—Å—ã–ª–∫–∏ —Ä—è–¥–æ–º —Å "Lat/Lon:"
  * —Å–æ–±–∏—Ä–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞ "Detail Information" (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 3‚Äì5 –∑–∞–ø–∏—Å–µ–π)
- –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –º–∞—Ä—à—Ä—É—Ç Google Maps –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º + –±–ª–æ–∫ Detail Information (–µ—Å–ª–∏ –µ—Å—Ç—å)

.env:
  TELEGRAM_TOKEN=...
  TELEGRAM_CHAT_ID=...
  COMM_CENTER=Inland
  POLL_INTERVAL=30
  TYPE_REGEX=Collision
"""

import os
import re
import time
import json
import datetime as dt
from typing import List, Dict, Optional, Tuple

import requests
from bs4 import BeautifulSoup

try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

BASE_URL = os.getenv("CHP_URL", "https://cad.chp.ca.gov/Traffic.aspx")
COMM_CENTER = os.getenv("COMM_CENTER", "Inland")

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "").strip()
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "").strip()

TYPE_REGEX = os.getenv("TYPE_REGEX", r"Collision")
AREA_REGEX = os.getenv("AREA_REGEX", r"")
LOCATION_REGEX = os.getenv("LOCATION_REGEX", r"")

POLL_INTERVAL = int(os.getenv("POLL_INTERVAL", "30"))
SEEN_FILE = os.getenv("SEEN_FILE", "seen.json")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0 Safari/537.36"
}

# ---------- —É—Ç–∏–ª–∏—Ç—ã —Ö—Ä–∞–Ω–µ–Ω–∏—è ----------
def load_seen() -> Dict[str, str]:
    try:
        with open(SEEN_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def save_seen(seen: Dict[str, str]) -> None:
    if len(seen) > 5000:
        keys = list(seen.keys())[-2000:]
        seen = {k: seen[k] for k in keys}
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(seen, f, ensure_ascii=False, indent=2)

def send_telegram(text: str) -> None:
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        print("[WARN] TELEGRAM_TOKEN/CHAT_ID –Ω–µ –∑–∞–¥–∞–Ω—ã. –°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ:\n", text)
        return
    api = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {"chat_id": TELEGRAM_CHAT_ID, "text": text, "disable_web_page_preview": True}
    try:
        r = requests.post(api, data=payload, timeout=20)
        if r.status_code != 200:
            print("[ERR] Telegram API status:", r.status_code, r.text[:200])
    except Exception as e:
        print("[ERR] Telegram send error:", e)

# ---------- —Ä–∞–±–æ—Ç–∞ —Å —Ñ–æ—Ä–º–æ–π ASP.NET ----------
def extract_form_state(soup: BeautifulSoup):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (action_url, payload) —Å–æ –≤—Å–µ–º–∏ —Å–∫—Ä—ã—Ç—ã–º–∏ –ø–æ–ª—è–º–∏ —Ñ–æ—Ä–º—ã (__VIEWSTATE, –∏ —Ç.–¥.)"""
    form = soup.find("form")
    if not form:
        raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω <form> –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
    action = form.get("action") or BASE_URL
    payload: Dict[str, str] = {}
    for inp in form.find_all("input"):
        name = inp.get("name")
        if not name:
            continue
        t = (inp.get("type") or "").lower()
        if t in ("submit", "button", "image"):
            continue
        if t in ("checkbox", "radio"):
            if inp.has_attr("checked"):
                payload[name] = inp.get("value", "on")
        else:
            payload[name] = inp.get("value", "")
    for sel in form.find_all("select"):
        name = sel.get("name")
        if not name:
            continue
        opt = sel.find("option", selected=True) or sel.find("option")
        if opt:
            payload[name] = opt.get("value", opt.get_text(strip=True))
    for ta in form.find_all("textarea"):
        name = ta.get("name")
        if not name:
            continue
        payload[name] = ta.get_text()
    return action, payload

def choose_communications_center(session: requests.Session) -> str:
    """–û—Ç–∫—Ä—ã–≤–∞–µ—Ç –≥–ª–∞–≤–Ω—É—é, –≤—ã–±–∏—Ä–∞–µ—Ç COMM_CENTER, –∂–º—ë—Ç OK, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML —Å–æ —Å–ø–∏—Å–∫–æ–º –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤."""
    r = session.get(BASE_URL, headers=HEADERS, timeout=30)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")
    action, payload = extract_form_state(soup)

    # –Ω–∞—Ö–æ–¥–∏–º —Å–µ–ª–µ–∫—Ç –¥–ª—è "Communications Centers"
    def looks_like_comm_select(sel) -> bool:
        text = (sel.find_previous(string=True) or "") + " " + (sel.find_next(string=True) or "")
        return "communications" in str(text).lower() and "center" in str(text).lower()

    selects = soup.find_all("select")
    if not selects:
        raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ <select> –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")

    comm_select = None
    for sel in selects:
        if looks_like_comm_select(sel):
            comm_select = sel
            break
    if comm_select is None:
        comm_select = selects[0]

    # –≤—ã–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞ –ø–æ –∏–º–µ–Ω–∏
    option_value = None
    target = COMM_CENTER.strip().lower()
    for opt in comm_select.find_all("option"):
        label = opt.get_text(strip=True).lower()
        if target in label:
            option_value = opt.get("value") or opt.get_text(strip=True)
            break
    if not option_value:
        raise RuntimeError(f"–ù–µ –Ω–∞—à—ë–ª Communications Center '{COMM_CENTER}'")

    payload[comm_select.get("name")] = option_value

    # –∂–º—ë–º OK (submit)
    form = soup.find("form")
    submit_name = None
    submit_value = None
    for btn in form.find_all("input", {"type": "submit"}):
        val = (btn.get("value") or "").strip().lower()
        if val in ("ok", "submit", "go"):
            submit_name = btn.get("name")
            submit_value = btn.get("value")
            break
    if not submit_name:
        btn = form.find("input", {"type": "submit"})
        if btn:
            submit_name = btn.get("name")
            submit_value = btn.get("value", "OK")
    if submit_name:
        payload[submit_name] = submit_value

    post_url = requests.compat.urljoin(BASE_URL, action)
    r2 = session.post(post_url, data=payload, headers=HEADERS, timeout=30)
    r2.raise_for_status()
    return r2.text

# ---------- –ø–∞—Ä—Å–∏–Ω–≥ —Ç–∞–±–ª–∏—Ü—ã –∏ postback Details ----------
def find_incidents_table(soup: BeautifulSoup):
    for table in soup.find_all("table"):
        header = table.find("tr")
        if not header:
            continue
        headers = [h.get_text(strip=True).lower() for h in header.find_all(["th", "td"])]
        if headers and all(x in headers for x in ["time", "type", "location"]):
            return table
    return None

def parse_incidents_with_postbacks(html: str):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç soup –∏ —Å–ø–∏—Å–æ–∫ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤, –≥–¥–µ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã __doPostBack"""
    soup = BeautifulSoup(html, "html.parser")
    table = find_incidents_table(soup)
    if not table:
        return soup, []
    rows = table.find_all("tr")[1:]
    incidents: List[Dict[str, str]] = []
    for row in rows:
        cols = row.find_all("td")
        if len(cols) < 7:
            continue
        # –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞: "Details"
        a = cols[0].find("a")
        postback = None
        if a and a.get("href", "").startswith("javascript:__doPostBack"):
            m = re.search(r"__doPostBack\('([^']+)','([^']*)'\)", a["href"])
            if m:
                postback = {"target": m.group(1), "argument": m.group(2)}

        incidents.append({
            "no": cols[1].get_text(strip=True),
            "time": cols[2].get_text(strip=True),
            "type": cols[3].get_text(strip=True),
            "location": cols[4].get_text(strip=True),
            "locdesc": cols[5].get_text(strip=True),
            "area": cols[6].get_text(strip=True),
            "postback": postback
        })
    return soup, incidents

# ---------- —Ä–∞–∑–±–æ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã Details ----------
def extract_coords_from_details_html(soup: BeautifulSoup) -> Optional[Tuple[float, float]]:
    """–ò–∑ –±–ª–æ–∫–∞ Details –¥–æ—Å—Ç–∞—ë–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ —Å—Å—ã–ª–∫–∏ —Ä—è–¥–æ–º —Å 'Lat/Lon:'"""
    label = soup.find(string=re.compile(r"Lat\s*/?\s*Lon", re.IGNORECASE))
    a = None
    if label:
        parent = getattr(label, "parent", None)
        if parent:
            a = parent.find("a", href=True) or parent.find_next("a", href=True)
    if not a:
        # –∑–∞–ø–∞—Å–Ω–æ–π –ø–æ–∏—Å–∫ –ª—é–±–æ–π —Å—Å—ã–ª–∫–∏ —Å –≤–∏–¥–∞ '34.123 -117.456'
        a = soup.find("a", href=True, string=re.compile(r"[-+]?\d+(?:\.\d+)?\s+[-+]?\d+(?:\.\d+)?"))
    if not a:
        return None

    nums = re.findall(r"[-+]?\d+(?:\.\d+)?", a.get_text(strip=True))
    if len(nums) >= 2:
        lat, lon = float(nums[0]), float(nums[1])
        if -90 <= lat <= 90 and -180 <= lon <= 180:
            return (lat, lon)
    return None

def extract_detail_information_text(soup: BeautifulSoup, max_lines: int = 4) -> Optional[List[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –∏–∑ –±–ª–æ–∫–∞ 'Detail Information' (–≤–µ—Ä—Ö–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_lines).
    –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ 'Detail Information' –∏ –±–µ—Ä—ë–º —Ç–µ–∫—Å—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ 'Unit Information' (–µ—Å–ª–∏ –µ—Å—Ç—å).
    """
    flat = soup.get_text("\n", strip=True)
    # –ù–∞–π—Ç–∏ –Ω–∞—á–∞–ª–æ –±–ª–æ–∫–∞
    m_start = re.search(r"(?im)^Detail Information$", flat)
    if not m_start:
        return None
    start = m_start.end()

    # –ù–∞–π—Ç–∏ –∫–æ–Ω–µ—Ü –±–ª–æ–∫–∞
    m_end = re.search(r"(?im)^(Unit Information|Close)$", flat[start:])
    end = start + (m_end.start() if m_end else len(flat) - start)

    block = flat[start:end]
    lines = [ln.strip() for ln in block.splitlines() if ln.strip()]
    # —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞: "8:45 AM    3    [13] ...", "8:23 AM   2   On RS" –∏ —Ç.–ø.
    # –û—Å—Ç–∞–≤–∏–º –ø–µ—Ä–≤—ã–µ max_lines (–æ–±—ã—á–Ω–æ –≤ –ø–æ—Ä—è–¥–∫–µ –æ—Ç –Ω–æ–≤–æ–≥–æ –∫ —Å—Ç–∞—Ä–æ–º—É)
    if not lines:
        return None
    return lines[:max_lines]

def fetch_details_by_postback(session: requests.Session, action_url: str, base_payload: Dict[str, str],
                              target: str, argument: str) -> Tuple[Optional[Tuple[float, float]], Optional[List[str]]]:
    """–ò–º–∏—Ç–∞—Ü–∏—è –∫–ª–∏–∫–∞ –ø–æ 'Details': –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (coords, detail_info_lines)"""
    payload = base_payload.copy()
    payload["__EVENTTARGET"] = target
    payload["__EVENTARGUMENT"] = argument
    post_url = requests.compat.urljoin(BASE_URL, action_url)
    r = session.post(post_url, data=payload, headers=HEADERS, timeout=30)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")
    coords = extract_coords_from_details_html(soup)
    info_lines = extract_detail_information_text(soup, max_lines=4)
    return coords, info_lines

# ---------- —Ñ–∏–ª—å—Ç—Ä—ã/—Ñ–æ—Ä–º–∞—Ç ----------
def filter_collisions(incidents: List[Dict[str, str]]) -> List[Dict[str, str]]:
    type_re = re.compile(TYPE_REGEX, re.IGNORECASE) if TYPE_REGEX else None
    area_re = re.compile(AREA_REGEX, re.IGNORECASE) if AREA_REGEX else None
    loc_re = re.compile(LOCATION_REGEX, re.IGNORECASE) if LOCATION_REGEX else None
    result = []
    for x in incidents:
        ok = True
        if type_re and not type_re.search(x["type"]):
            ok = False
        if ok and area_re and not area_re.search(x["area"]):
            ok = False
        if ok and loc_re and not (loc_re.search(x["location"]) or loc_re.search(x["locdesc"])):
            ok = False
        if ok:
            result.append(x)
    return result

def make_key(inc: Dict[str, str]) -> str:
    today = dt.date.today().isoformat()
    return f"{today}:{inc['no']}:{inc['time']}:{inc['type']}"

def format_message(inc: Dict[str, str], latlon: Optional[Tuple[float, float]], details: Optional[List[str]]) -> str:
    parts = [
        f"üö® –î–¢–ü {inc['time']}",
        f"{inc['type']}",
        f"üìç {inc['location']} ‚Äî {inc['locdesc']}",
        f"üè∑Ô∏è {inc['area']}",
    ]
    if latlon:
        lat, lon = latlon
        parts.append(f"üó∫Ô∏è https://www.google.com/maps/dir/?api=1&destination={lat:.6f},{lon:.6f}&travelmode=driving")
    else:
        parts.append("üó∫Ô∏è –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

    if details:
        # –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –≤—ã–≤–µ–¥–µ–º 3‚Äì4 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç—Ä–æ–∫–∏
        parts.append("üìù Detail Information:")
        for ln in details:
            parts.append(f"‚Ä¢ {ln}")

    return "\n".join(parts)

# ---------- –≥–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª ----------
def main() -> None:
    print(f"[INFO] CHP notifier v5.1 started. Center: {COMM_CENTER} | Interval: {POLL_INTERVAL}s")
    seen = load_seen()
    last_day = dt.date.today()
    session = requests.Session()

    while True:
        try:
            if dt.date.today() != last_day:
                seen = {}
                last_day = dt.date.today()
                save_seen(seen)

            # 1) —Ü–µ–Ω—Ç—Ä –∏ —Ç–∞–±–ª–∏—Ü–∞
            html = choose_communications_center(session)

            # 2) –ø–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫–∏ + –±–µ—Ä—ë–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ñ–æ—Ä–º—ã
            soup, incidents = parse_incidents_with_postbacks(html)
            action_url, base_payload = extract_form_state(soup)

            # 3) —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ Collision
            collisions = filter_collisions(incidents)

            new_count = 0
            for inc in collisions:
                key = make_key(inc)
                if key in seen:
                    continue

                latlon = None
                detail_lines = None
                if inc.get("postback"):
                    latlon, detail_lines = fetch_details_by_postback(
                        session, action_url, base_payload,
                        inc["postback"]["target"], inc["postback"]["argument"]
                    )

                send_telegram(format_message(inc, latlon, detail_lines))
                seen[key] = dt.datetime.utcnow().isoformat()
                new_count += 1

            if new_count:
                save_seen(seen)

            print(f"[{dt.datetime.now().strftime('%H:%M:%S')}] {COMM_CENTER}: rows={len(incidents)}, collisions={len(collisions)}, new={new_count}")
        except KeyboardInterrupt:
            print("\n[INFO] Stopped by user.")
            break
        except Exception as e:
            print("[ERR] loop error:", e)
        time.sleep(POLL_INTERVAL)

if __name__ == "__main__":
    main()
